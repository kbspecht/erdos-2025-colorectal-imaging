{"cells":[{"cell_type":"markdown","metadata":{"id":"ELZsV9X4CpjR"},"source":["This file contains single frame and sequence data. It is using the data found under detection2_clean/yolo_split2. The augmentations for this file mimic those found in polyp_alb352_cos.yaml. (Note: There is no cosine learning rate here.)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"IG0-FPSw0BTj","executionInfo":{"status":"ok","timestamp":1761388707894,"user_tz":-180,"elapsed":15340,"user":{"displayName":"Rebekah Eichberg","userId":"10093971884303200083"}}},"outputs":[],"source":["%%capture\n","!pip install torch torchvision albumentations pycocotools opencv-python ultralytics"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20199,"status":"ok","timestamp":1761388728097,"user":{"displayName":"Rebekah Eichberg","userId":"10093971884303200083"},"user_tz":-180},"id":"AVgyjTOy0EZv","outputId":"bf126769-9a35-4b35-ed1a-11136a1c7d4c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"]}],"source":["import torch, ultralytics\n","#!/usr/bin/env python3\n","import os, sys, json, random, shutil\n","from pathlib import Path\n","import re\n","import cv2\n","import yaml\n","from skimage.measure import label, regionprops\n","from ultralytics import YOLO\n","\n","from typing import Tuple, Dict, List\n","from PIL import Image\n","import torch\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","from PIL import Image, ImageDraw\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from albumentations.core.serialization import from_dict\n","\n","from torch.utils.data import Dataset, DataLoader\n","\n","import matplotlib.pyplot as plt\n","from matplotlib.patches import Rectangle\n","\n","from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN\n","from torchvision.models.detection.rpn import AnchorGenerator\n","from torchvision.ops import box_iou, nms"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40487,"status":"ok","timestamp":1761388768592,"user":{"displayName":"Rebekah Eichberg","userId":"10093971884303200083"},"user_tz":-180},"id":"KTG9q7Hk0Gdg","outputId":"3a542ac0-cc49-4f86-f6bc-05129a0254bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"lSjh34fx0VZY","executionInfo":{"status":"ok","timestamp":1761388768594,"user_tz":-180,"elapsed":3,"user":{"displayName":"Rebekah Eichberg","userId":"10093971884303200083"}}},"outputs":[],"source":["ROOT = Path(\"/content/drive/MyDrive/ErdosFall25/\")"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"oj4Q0-6b08sE","executionInfo":{"status":"ok","timestamp":1761388768706,"user_tz":-180,"elapsed":111,"user":{"displayName":"Rebekah Eichberg","userId":"10093971884303200083"}}},"outputs":[],"source":["# Fix the seed\n","def set_seed(s=42):\n","    random.seed(s); np.random.seed(s); torch.manual_seed(s); torch.cuda.manual_seed_all(s)\n","set_seed(42)\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"o-FJoQzoDk_U"},"source":["Convert YOLO Labels to COCO JSON files. The files are already created and the code is commented out."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Y28pUnKJ1VGG","executionInfo":{"status":"ok","timestamp":1761388768718,"user_tz":-180,"elapsed":11,"user":{"displayName":"Rebekah Eichberg","userId":"10093971884303200083"}}},"outputs":[],"source":["from pathlib import Path\n","import json\n","from PIL import Image\n","\n","def yolo_to_coco(images_dir, labels_dir, out_json, class_name=\"polyp\"):\n","    \"\"\"\n","    Convert YOLO .txt (class cx cy w h normalized) -> COCO JSON (for detection).\n","    \"\"\"\n","    images, annotations = [], []\n","    categories = [{\"id\": 1, \"name\": class_name}]\n","    ann_id, img_id = 1, 1\n","\n","    images_dir, labels_dir = Path(images_dir), Path(labels_dir)\n","    img_exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n","\n","    for img_path in sorted(images_dir.rglob(\"*\")):\n","        if img_path.suffix.lower() not in img_exts:\n","            continue\n","        W, H = Image.open(img_path).size\n","        images.append({\n","            \"id\": img_id,\n","            \"file_name\": str(img_path.resolve()),\n","            \"width\": W,\n","            \"height\": H\n","        })\n","\n","        label_file = labels_dir / f\"{img_path.stem}.txt\"\n","        if label_file.exists():\n","            with open(label_file) as f:\n","                for line in f:\n","                    parts = line.strip().split()\n","                    if len(parts) != 5:\n","                        continue\n","                    cls, xc, yc, w, h = map(float, parts)\n","                    x = (xc - w/2) * W\n","                    y = (yc - h/2) * H\n","                    w *= W\n","                    h *= H\n","                    annotations.append({\n","                        \"id\": ann_id,\n","                        \"image_id\": img_id,\n","                        \"category_id\": 1,\n","                        \"bbox\": [x, y, w, h],\n","                        \"area\": float(w * h),\n","                        \"iscrowd\": 0\n","                    })\n","                    ann_id += 1\n","        img_id += 1\n","\n","    coco = {\"images\": images, \"annotations\": annotations, \"categories\": categories}\n","    out_json = Path(out_json)\n","    out_json.parent.mkdir(parents=True, exist_ok=True)\n","    with open(out_json, \"w\") as f:\n","        json.dump(coco, f)\n","    print(f\"Wrote {out_json} ({len(images)} images, {len(annotations)} boxes).\")\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"KWNxZwNE1hDo","colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"status":"error","timestamp":1761390206445,"user_tz":-180,"elapsed":1437724,"user":{"displayName":"Rebekah Eichberg","userId":"10093971884303200083"}},"outputId":"ff5f7812-361c-458b-a136-8ec6578ab30c"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4212812425.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# # train json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0myolo_to_coco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"data/detection2/yolo_split2/train/images\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mROOT\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"data/detection2/yolo_split2/train/labels\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mROOT\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"data/detection2/yolo_split2/train/annotations.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipython-input-3027624082.py\u001b[0m in \u001b[0;36myolo_to_coco\u001b[0;34m(images_dir, labels_dir, out_json, class_name)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlabel_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                     \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# # train json\n","yolo_to_coco(ROOT/\"data/detection2/yolo_split2/train/images\", ROOT/\"data/detection2/yolo_split2/train/labels\", ROOT/\"data/detection2/yolo_split2/train/annotations.json\")\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"12D6yYNg4_F7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761391230562,"user_tz":-180,"elapsed":1017907,"user":{"displayName":"Rebekah Eichberg","userId":"10093971884303200083"}},"outputId":"747dc1f8-37f7-4ee2-b1f4-9556179e1e08"},"outputs":[{"output_type":"stream","name":"stdout","text":["Wrote /content/drive/MyDrive/ErdosFall25/data/detection2/yolo_split2/val/annotations.json (1666 images, 1446 boxes).\n"]}],"source":["# # valid json\n","yolo_to_coco(ROOT/\"data/detection2/yolo_split2/val/images\", ROOT/\"data/detection2/yolo_split2/val/labels\", ROOT/\"data/detection2/yolo_split2/val/annotations.json\")"]},{"cell_type":"markdown","metadata":{"id":"ecf-ERF5CVX2"},"source":["Load in JSON Files Annotations + Betul's Aug YAML File + Visualizer for Sanity Check"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xV42wHK6BYd2"},"outputs":[],"source":["ANNOTATIONS_ROOT  = Path(\"/content/drive/MyDrive/ErdosFall25/data/detection2_clean/yolo_split2\")\n","TRAIN_JSON        = ANNOTATIONS_ROOT / \"train\" / \"annotations.json\"\n","VAL_JSON          = ANNOTATIONS_ROOT / \"val\"   / \"annotations.json\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iLg7-a9bD5uT"},"outputs":[],"source":["# function to load in yaml file with option to normalize to tensor\n","# that is mean 0 and std 1 with max pixel value of 255.0\n","\n","def load_albu_yaml(yaml_path, section=\"albumentations\",\n","                   add_normalize_to_tensor=True,\n","                   use_masks=False,               # set True only if you'll pass masks to tfm(...)\n","                   min_visibility=0.001):          # drop near-vanishing boxes on train\n","\n","    with open(yaml_path, \"r\") as f:\n","        cfg = yaml.safe_load(f)\n","    if section not in cfg:\n","        raise KeyError(f\"YAML has keys {list(cfg.keys())}, but not '{section}'\")\n","\n","    compose_dict = cfg[section]\n","\n","    # --- tiny compatibility tweaks on the raw dict (no re-writes to your file) ---\n","    def _fix_inplace(node):\n","        if isinstance(node, dict):\n","            cf = node.get(\"__class_fullname__\", \"\")\n","            name = cf.split(\".\")[-1] if cf else \"\"\n","\n","            # 1) ShiftScaleRotate => Affine (albu now prefers Affine)\n","            if name == \"ShiftScaleRotate\":\n","                # Replace class\n","                node[\"__class_fullname__\"] = \"albumentations.augmentations.geometric.transforms.Affine\"\n","                # Map limits to Affine ranges\n","                shift = float(node.pop(\"shift_limit\", 0.0))\n","                scale = float(node.pop(\"scale_limit\", 0.0))\n","                rot   = float(node.pop(\"rotate_limit\", 0.0))\n","                node[\"translate_percent\"] = (-abs(shift), abs(shift))\n","                node[\"scale\"]             = (1-abs(scale), 1+abs(scale))\n","                node[\"rotate\"]            = (-abs(rot), abs(rot))\n","                # Keep border/interp if present\n","                # Albumentations uses 'mode' for border in Affine; reuse existing if given\n","                if \"border_mode\" in node:\n","                    node[\"mode\"] = node.pop(\"border_mode\")\n","\n","            # 2) GaussNoise: some versions reject 'mean'\n","            if name == \"GaussNoise\":\n","                if \"var_limit\" in node and isinstance(node[\"var_limit\"], list):\n","                    node[\"var_limit\"] = tuple(node[\"var_limit\"])\n","                # Drop mean if your installed albu doesn't accept it\n","                node.pop(\"mean\", None)\n","\n","            # 3) MaskDropout: if you are NOT passing masks, swap to CoarseDropout\n","            if name == \"MaskDropout\" and not use_masks:\n","                node[\"__class_fullname__\"] = \"albumentations.augmentations.dropout.coarse_dropout.CoarseDropout\"\n","                # Map a couple of sensible defaults\n","                node[\"max_holes\"]  = node.get(\"max_objects\", 1)\n","                node[\"min_holes\"]  = 1\n","                node[\"max_height\"] = node.get(\"max_height\", 64)\n","                node[\"max_width\"]  = node.get(\"max_width\", 64)\n","                node[\"min_height\"] = node.get(\"min_height\", 32)\n","                node[\"min_width\"]  = node.get(\"min_width\", 32)\n","                # CoarseDropout uses 'fill_value' only; keep if present\n","\n","            # Recurse to children\n","            for k, v in list(node.items()):\n","                _fix_inplace(v)\n","\n","        elif isinstance(node, list):\n","            for v in node:\n","                _fix_inplace(v)\n","\n","    _fix_inplace(compose_dict)\n","\n","    # Build the Compose from dict (now version-compatible)\n","    base = from_dict(compose_dict)  # -> A.Compose\n","\n","    # Add Normalize + ToTensorV2 at the end if you want\n","    if add_normalize_to_tensor:\n","        tail = [\n","            A.Normalize(mean=(0,0,0), std=(1,1,1), max_pixel_value=255.0),\n","            A.pytorch.ToTensorV2(),\n","        ]\n","        base = A.Compose(base.transforms + tail, p=base.p)\n","\n","    # Wrap with bbox params so boxes are transformed with the image\n","    wrapped = A.Compose(\n","        base.transforms,\n","        p=base.p,\n","        bbox_params=A.BboxParams(\n","            format=\"pascal_voc\",\n","            label_fields=[\"labels\"],\n","            min_visibility=min_visibility\n","        ),\n","        strict=False\n","    )\n","    return wrapped\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a31kIgjoDERv"},"outputs":[],"source":["# function to read in annotation file and make a dictionary containing\n","# image information (id, etc.)\n","def load_coco_state(ann_json, images_root=None):\n","  with open(ann_json, \"r\") as f:\n","    coco = json.load(f)\n","\n","  images = coco['images']\n","  anns = coco['annotations']\n","  cats = coco['categories']\n","\n","  anns_by_img = {}\n","  for a in anns:\n","    anns_by_img.setdefault(a['image_id'], []).append(a)\n","\n","  cat_id_to_idx = {c['id']: i+1 for i,c in enumerate(cats)}\n","  idx_to_cat_id = {i + 1: c['id'] for i,c in enumerate(cats)}\n","  num_classes = len(cats) + 1\n","\n","  state = {\n","      \"images\": images,\n","      \"anns_by_img\": anns_by_img,\n","      \"cat_id_to_idx\": cat_id_to_idx,\n","      \"idx_to_cat_id\" : idx_to_cat_id,\n","      \"num_classes\" : num_classes,\n","      \"images_root\": Path(images_root) if images_root else None\n","  }\n","\n","  return state"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kPTY-SdcGHdB"},"outputs":[],"source":["def _compose_with_bboxes(compose: A.Compose):\n","  return A.Compose(\n","      compose.transforms,\n","      p=compose.p,\n","      bbox_params = A.BboxParams(\n","          format='pascal_voc',\n","          label_fields = ['labels'],\n","          min_visibility=0.001\n","      ),\n","      strict = False\n","  )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zcOFBsSQGptN"},"outputs":[],"source":["def get_example(i, state, tfm: A.Compose):\n","\n","  imrec = state['images'][i]\n","  p = Path(imrec['file_name'])\n","\n","  if state['images_root'] and not p.is_absolute():\n","    p = state['images_root'] / p\n","\n","  img = cv2.imread(str(p))\n","  if img is None:\n","    raise FileNotFoundError(str(p))\n","\n","  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","  H, W = img.shape[:2]\n","\n","  boxes, labels = [], []\n","  for a in state['anns_by_img'].get(imrec['id'],[]):\n","    x, y, w, h = a['bbox']\n","    boxes.append([x, y , x + w , y + h])\n","    labels.append(state['cat_id_to_idx'][a['category_id']])\n","\n","  boxes  = np.asarray(boxes,  dtype=np.float32) if boxes else np.zeros((0,4), np.float32)\n","  labels = np.asarray(labels, dtype=np.int64)   if labels else np.zeros((0,),  np.int64)\n","\n","  if len(boxes) > 0:\n","    boxes[:, [0,2]] = np.clip(boxes[:, [0,2]], 0, W)\n","    boxes[:, [1,3]] = np.clip(boxes[:, [1,3]], 0, H)\n","    eps = 1e-6\n","    keep = (boxes[:,2]-boxes[:,0] > eps) & (boxes[:,3]-boxes[:,1] > eps)\n","    boxes, labels = boxes[keep], labels[keep]\n","\n","  kwargs = dict(image=img, bboxes=boxes.tolist(), labels=labels.tolist())\n","\n","  out = tfm(**kwargs)\n","\n","  bxs, lbs = out[\"bboxes\"], out[\"labels\"]\n","  boxes  = np.asarray(bxs, dtype=np.float32) if bxs else np.zeros((0,4), np.float32)\n","  labels = np.asarray(lbs, dtype=np.int64)   if lbs else np.zeros((0,),  np.int64)\n","\n","  target = {\n","      \"boxes\":    torch.as_tensor(boxes,  dtype=torch.float32),\n","      \"labels\":   torch.as_tensor(labels, dtype=torch.int64),\n","      \"image_id\": torch.tensor([imrec[\"id\"]], dtype=torch.int64),\n","  }\n","\n","  return out[\"image\"], target"]},{"cell_type":"markdown","metadata":{"id":"oiGA8slsERnP"},"source":["Begin Transfer Learning Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h2zfx8wJdS5C"},"outputs":[],"source":["def make_collate_fn(state, tfm):\n","\n","  tfm_with_boxes = _compose_with_bboxes(tfm)\n","\n","  def collate_fn(batch_indices):\n","    imgs, targs = [], []\n","    for idx in batch_indices:\n","      img, targ = get_example(idx, state, tfm_with_boxes)\n","      imgs.append(img)\n","      targs.append(targ)\n","    return imgs, targs\n","\n","  return collate_fn\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N6uqtrIuJuFo"},"outputs":[],"source":["def make_dataloader(state, tfm, batch_size = 1, shuffle = True, num_workers = 2, worker_seed = 42):\n","  N = len(state['images'])\n","  indices = list(range(N))\n","\n","  generator = None\n","  if shuffle:\n","    g = torch.Generator()\n","    g.manual_seed(worker_seed)\n","    generator = g\n","\n","  def _worker_init_fn(worker_id):\n","    import random\n","    base = worker_seed + worker_id * 9973\n","    np.random.seed(base % (2**32 - 1))\n","    random.seed(base)\n","\n","  return DataLoader(\n","      indices,\n","      batch_size=batch_size,\n","      shuffle=shuffle,\n","      num_workers=num_workers,\n","      worker_init_fn=_worker_init_fn if num_workers > 0 else None,\n","      generator=generator,\n","      collate_fn=make_collate_fn(state, tfm)\n","  )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vnzg9_FeOwno"},"outputs":[],"source":["# load in coco states\n","\n","train_state = load_coco_state(\n","    ann_json = TRAIN_JSON,\n","    images_root = ANNOTATIONS_ROOT / \"train\" / \"images\"\n",")\n","\n","val_state   = load_coco_state(\n","    ann_json = VAL_JSON,\n","    images_root = ANNOTATIONS_ROOT / \"val\"   / \"images\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1286,"status":"ok","timestamp":1761305639126,"user":{"displayName":"Rebekah Eichberg","userId":"10093971884303200083"},"user_tz":-180},"id":"a3z5_zccLBIk","outputId":"24443bc5-4f93-4b9d-afdf-2d44cfeaf3cb"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/albumentations/core/serialization.py:185: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n","  return cls(**args)\n","/usr/local/lib/python3.12/dist-packages/albumentations/core/serialization.py:185: UserWarning: Argument(s) 'mode' are not valid for transform Affine\n","  return cls(**args)\n","/usr/local/lib/python3.12/dist-packages/albumentations/core/serialization.py:185: UserWarning: Argument(s) 'max_objects, fill_value, mask_fill_value, max_holes, min_holes, max_height, max_width, min_height, min_width' are not valid for transform CoarseDropout\n","  return cls(**args)\n"]}],"source":["aug_yaml_path = \"/content/drive/.shortcut-targets-by-id/1sNBAVjJw_53OufvKWiqpnmt9aFuzBIrw/configs/polyp_alb352_cos.yaml\"\n","train_tfm = load_albu_yaml(aug_yaml_path, add_normalize_to_tensor=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48,"status":"ok","timestamp":1761305639189,"user":{"displayName":"Rebekah Eichberg","userId":"10093971884303200083"},"user_tz":-180},"id":"UIiJs9ar79AI","outputId":"a2670204-1da1-4649-c752-61a0684cf696"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-3994576462.py:3: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n","  A.PadIfNeeded(min_height=352, min_width=352,\n"]}],"source":["train_tfm = A.Compose(\n","    [\n","        A.PadIfNeeded(min_height=352, min_width=352,\n","                      border_mode=cv2.BORDER_CONSTANT, value=0, p=1.0)\n","    ] + train_tfm.transforms,\n","    p=train_tfm.p,\n","    bbox_params=A.BboxParams(format=\"pascal_voc\",\n","                             label_fields=[\"labels\"],\n","                             min_visibility=0.001),\n","    strict=False\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1761305639140,"user":{"displayName":"Rebekah Eichberg","userId":"10093971884303200083"},"user_tz":-180},"id":"tyuEffX4Ovhb","outputId":"8882d153-3d4c-4454-9513-42eb325a1c8f"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-1484047654.py:3: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n","  A.PadIfNeeded(min_height=352, min_width=352,\n"]}],"source":["val_tfm = A.Compose([\n","    A.LongestMaxSize(max_size=352, p=1.0),\n","    A.PadIfNeeded(min_height=352, min_width=352,\n","                  border_mode=cv2.BORDER_CONSTANT, value=0, p=1.0),\n","    A.Normalize(mean=(0,0,0), std=(1,1,1), max_pixel_value=255.0),\n","    A.pytorch.ToTensorV2(),\n","], bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"labels\"], min_visibility=0.0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pChZWJtSPByt"},"outputs":[],"source":["train_loader = make_dataloader(\n","    state=train_state,\n","    tfm=train_tfm,\n","    batch_size=1,\n","    shuffle=True,\n","    num_workers=2\n",")\n","\n","val_loader = make_dataloader(\n","    state=val_state,\n","    tfm=val_tfm,\n","    batch_size=1,\n","    shuffle=True, # do we want shuffle on val?\n","    num_workers=2\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2309,"status":"ok","timestamp":1761305641498,"user":{"displayName":"Rebekah Eichberg","userId":"10093971884303200083"},"user_tz":-180},"id":"UeqV7H0_EsnR","outputId":"830d9f68-f01d-408b-d9e8-95e7c0170aa3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 160M/160M [00:00<00:00, 192MB/s]\n"]}],"source":["from torchvision.models.detection import fasterrcnn_resnet50_fpn\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# a) load COCO-pretrained model\n","model = fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n","\n","# b) replace detection head (num_classes = background + polyp = 2)\n","in_feats = model.roi_heads.box_predictor.cls_score.in_features\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_feats, num_classes=2)\n","\n","# c) (transfer learning) freeze backbone params → only train the head\n","for p in model.backbone.parameters():\n","    p.requires_grad = False\n","\n","trainable_param_names = []\n","for name, p in model.named_parameters():\n","    if p.requires_grad:\n","        trainable_param_names.append(name)\n","\n","model = model.to(DEVICE)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1761305641502,"user":{"displayName":"Rebekah Eichberg","userId":"10093971884303200083"},"user_tz":-180},"id":"Lqxcw2UAFg-O","outputId":"2f10ad9e-bb56-4f97-d788-5f411af4a463"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-1509385352.py:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE.type==\"cuda\"))\n"]}],"source":["# train only trainable params (the head)\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.AdamW(params, lr=1e-4, weight_decay=1e-4)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)  # optional\n","scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE.type==\"cuda\"))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ry5K3LnZc0j4"},"outputs":[],"source":["import math, time\n","from tqdm.auto import tqdm\n","\n","def train_one_epoch(model, loader, optimizer, scaler, max_norm=2.0):\n","    model.train()\n","    running = 0.0\n","    for images, targets in tqdm(loader, desc=\"Train\", leave=False):\n","        images  = [im.to(DEVICE) for im in images]\n","        targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n","\n","        optimizer.zero_grad(set_to_none=True)\n","        with torch.amp.autocast('cuda', enabled=(DEVICE.type == 'cuda')):\n","            loss_dict = model(images, targets)\n","            loss = sum(loss_dict.values())\n","\n","        scaler.scale(loss).backward()\n","        # gradient clipping (just in case)\n","        scaler.unscale_(optimizer)\n","        torch.nn.utils.clip_grad_norm_( [p for p in model.parameters() if p.requires_grad], max_norm )\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        running += loss.item()\n","    return running / max(1, len(loader))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":643,"referenced_widgets":["e2d4e2b4895b4d1b9c36efc460bee753","b42491b642dc444ca2be6d81509212f6","702e0a41a95049b892b6aed1a632d4e6","be221bc7f8414b2084123de01b0066ee","7c22e7602dbb4c579486592bd368032e","247549826d45430da46b245c1d619c5f","6e0aa39b4d9e4108a1734c5e0cda2e3e","5ef6a8f76ba04ad7a9ce20f6c3fe70f3","5d0935170e2047bb83fb78c741e81075","c3f74de924ea48e9855a5529d130b953","fecd0a0664a34d59bc53b02dd0423adb","1735807ded694b60a4a642aac803dbe0","bf99a10cac15491491ee550a6fb2cf6e","968acb627f28424291917f4bed92f36a","9ba8a9df754a4eff8113ccde9d82f17e","a60dcce7b6be42bfb54530c81a6ba620","9c269b2cb484442d8019be2718d5521e","224b61dbb3464ca69eb4ff2980a58f0d","83bf3697f7f64ff2bfcdea0964db34cb","8a0baafe0b5f427c9708bcecece78897","4f9a82ad65694719aad40dc76a020342","9cc391023ded43cf8a489029d4579ba8","a8bbdc41fea54a83bd5707e20554cded","e328b3054dfe421881ffb4961ddf4855","a3884dcbb32b43ecbdf20590a5d8dd22","3c035419edfe4d18ae0e4566a400ee15","069aa2dd531540abb060a71a91a84a37","9781f9ebf23d4c0bb3162102e2098bb8","94c5a6b94d9d4deaa04623a744962b63","d7181656aeb940e78613504569ec88f9","3b022947e6d14b0f9e34a31757ed1f63","d147178aa9914cc6a7270be97a78d0f5","548929578f284b9b9ba2ac901225d55b","a952e9ac80284359a0b7483c14599421","85c3084647274ecb9da3fdadc897e03e"]},"id":"vjNCI3z8RTDw","outputId":"43a87e08-d047-4152-a755-10dc217f4d90"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e2d4e2b4895b4d1b9c36efc460bee753","version_major":2,"version_minor":0},"text/plain":["Train:   0%|          | 0/4169 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1/5 | train_loss=0.0730 | time=1395.4s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1735807ded694b60a4a642aac803dbe0","version_major":2,"version_minor":0},"text/plain":["Train:   0%|          | 0/4169 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7839bc264c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n","    if w.is_alive():\n","       ^^^^^^^^^^^^\n","  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7839bc264c20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n","    if w.is_alive():\n","       ^^^^^^^^^^^^\n","  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","AssertionError: can only test a child process\n","/usr/local/lib/python3.12/dist-packages/albumentations/augmentations/dropout/functional.py:559: RuntimeWarning: invalid value encountered in divide\n","  visibility_ratios = remaining_areas / box_areas\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/5 | train_loss=0.0631 | time=324.8s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a8bbdc41fea54a83bd5707e20554cded","version_major":2,"version_minor":0},"text/plain":["Train:   0%|          | 0/4169 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/albumentations/augmentations/dropout/functional.py:559: RuntimeWarning: invalid value encountered in divide\n","  visibility_ratios = remaining_areas / box_areas\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/5 | train_loss=0.0666 | time=314.0s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a952e9ac80284359a0b7483c14599421","version_major":2,"version_minor":0},"text/plain":["Train:   0%|          | 0/4169 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4/5 | train_loss=0.0739 | time=311.6s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"85c3084647274ecb9da3fdadc897e03e","version_major":2,"version_minor":0},"text/plain":["Train:   0%|          | 0/4169 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 5/5 | train_loss=0.0730 | time=309.6s\n","Saved: artifacts/model_best.pth artifacts/model_last.pth\n"]}],"source":["EPOCHS = 5\n","ART = Path(\"./artifacts\"); ART.mkdir(exist_ok=True, parents=True)\n","\n","with open(ART/\"idx_to_cat_id.json\",\"w\") as f: json.dump(train_state[\"idx_to_cat_id\"], f)\n","\n","best_path = ART/\"model_best.pth\"\n","last_path = ART/\"model_last.pth\"\n","best_loss = float(\"inf\")\n","\n","for ep in range(1, EPOCHS+1):\n","    t0 = time.time()\n","    tr_loss = train_one_epoch(model, train_loader, optimizer, scaler)\n","    scheduler.step()\n","    torch.save(model.state_dict(), last_path)  # checkpoint each epoch\n","    if tr_loss < best_loss:\n","        best_loss = tr_loss\n","        torch.save(model.state_dict(), best_path)\n","    print(f\"Epoch {ep}/{EPOCHS} | train_loss={tr_loss:.4f} | time={time.time()-t0:.1f}s\")\n","\n","print(\"Saved:\", best_path, last_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"pP_p_HieQg1h","outputId":"9301559b-d676-490f-c222-82b526894b0c"},"outputs":[{"ename":"RuntimeError","evalue":"Error(s) in loading state_dict for FasterRCNN:\n\tMissing key(s) in state_dict: \"backbone.fpn.inner_blocks.0.1.weight\", \"backbone.fpn.inner_blocks.0.1.bias\", \"backbone.fpn.inner_blocks.0.1.running_mean\", \"backbone.fpn.inner_blocks.0.1.running_var\", \"backbone.fpn.inner_blocks.1.1.weight\", \"backbone.fpn.inner_blocks.1.1.bias\", \"backbone.fpn.inner_blocks.1.1.running_mean\", \"backbone.fpn.inner_blocks.1.1.running_var\", \"backbone.fpn.inner_blocks.2.1.weight\", \"backbone.fpn.inner_blocks.2.1.bias\", \"backbone.fpn.inner_blocks.2.1.running_mean\", \"backbone.fpn.inner_blocks.2.1.running_var\", \"backbone.fpn.inner_blocks.3.1.weight\", \"backbone.fpn.inner_blocks.3.1.bias\", \"backbone.fpn.inner_blocks.3.1.running_mean\", \"backbone.fpn.inner_blocks.3.1.running_var\", \"backbone.fpn.layer_blocks.0.1.weight\", \"backbone.fpn.layer_blocks.0.1.bias\", \"backbone.fpn.layer_blocks.0.1.running_mean\", \"backbone.fpn.layer_blocks.0.1.running_var\", \"backbone.fpn.layer_blocks.1.1.weight\", \"backbone.fpn.layer_blocks.1.1.bias\", \"backbone.fpn.layer_blocks.1.1.running_mean\", \"backbone.fpn.layer_blocks.1.1.running_var\", \"backbone.fpn.layer_blocks.2.1.weight\", \"backbone.fpn.layer_blocks.2.1.bias\", \"backbone.fpn.layer_blocks.2.1.running_mean\", \"backbone.fpn.layer_blocks.2.1.running_var\", \"backbone.fpn.layer_blocks.3.1.weight\", \"backbone.fpn.layer_blocks.3.1.bias\", \"backbone.fpn.layer_blocks.3.1.running_mean\", \"backbone.fpn.layer_blocks.3.1.running_var\", \"rpn.head.conv.1.0.weight\", \"rpn.head.conv.1.0.bias\", \"roi_heads.box_head.0.0.weight\", \"roi_heads.box_head.0.1.weight\", \"roi_heads.box_head.0.1.bias\", \"roi_heads.box_head.0.1.running_mean\", \"roi_heads.box_head.0.1.running_var\", \"roi_heads.box_head.1.0.weight\", \"roi_heads.box_head.1.1.weight\", \"roi_heads.box_head.1.1.bias\", \"roi_heads.box_head.1.1.running_mean\", \"roi_heads.box_head.1.1.running_var\", \"roi_heads.box_head.2.0.weight\", \"roi_heads.box_head.2.1.weight\", \"roi_heads.box_head.2.1.bias\", \"roi_heads.box_head.2.1.running_mean\", \"roi_heads.box_head.2.1.running_var\", \"roi_heads.box_head.3.0.weight\", \"roi_heads.box_head.3.1.weight\", \"roi_heads.box_head.3.1.bias\", \"roi_heads.box_head.3.1.running_mean\", \"roi_heads.box_head.3.1.running_var\", \"roi_heads.box_head.5.weight\", \"roi_heads.box_head.5.bias\". \n\tUnexpected key(s) in state_dict: \"backbone.fpn.inner_blocks.0.0.bias\", \"backbone.fpn.inner_blocks.1.0.bias\", \"backbone.fpn.inner_blocks.2.0.bias\", \"backbone.fpn.inner_blocks.3.0.bias\", \"backbone.fpn.layer_blocks.0.0.bias\", \"backbone.fpn.layer_blocks.1.0.bias\", \"backbone.fpn.layer_blocks.2.0.bias\", \"backbone.fpn.layer_blocks.3.0.bias\", \"roi_heads.box_head.fc6.weight\", \"roi_heads.box_head.fc6.bias\", \"roi_heads.box_head.fc7.weight\", \"roi_heads.box_head.fc7.bias\". ","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1096100062.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfasterrcnn_resnet50_fpn_v2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfasterrcnn_resnet50_fpn_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_classes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWEIGHTS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2623\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2624\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2625\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2626\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for FasterRCNN:\n\tMissing key(s) in state_dict: \"backbone.fpn.inner_blocks.0.1.weight\", \"backbone.fpn.inner_blocks.0.1.bias\", \"backbone.fpn.inner_blocks.0.1.running_mean\", \"backbone.fpn.inner_blocks.0.1.running_var\", \"backbone.fpn.inner_blocks.1.1.weight\", \"backbone.fpn.inner_blocks.1.1.bias\", \"backbone.fpn.inner_blocks.1.1.running_mean\", \"backbone.fpn.inner_blocks.1.1.running_var\", \"backbone.fpn.inner_blocks.2.1.weight\", \"backbone.fpn.inner_blocks.2.1.bias\", \"backbone.fpn.inner_blocks.2.1.running_mean\", \"backbone.fpn.inner_blocks.2.1.running_var\", \"backbone.fpn.inner_blocks.3.1.weight\", \"backbone.fpn.inner_blocks.3.1.bias\", \"backbone.fpn.inner_blocks.3.1.running_mean\", \"backbone.fpn.inner_blocks.3.1.running_var\", \"backbone.fpn.layer_blocks.0.1.weight\", \"backbone.fpn.layer_blocks.0.1.bias\", \"backbone.fpn.layer_blocks.0.1.running_mean\", \"backbone.fpn.layer_blocks.0.1.running_var\", \"backbone.fpn.layer_blocks.1.1.weight\", \"backbone.fpn.layer_blocks.1.1.bias\", \"backbone.fpn.layer_blocks.1.1.running_mean\", \"backbone.fpn.layer_blocks.1.1.running_var\", \"backbone.fpn.layer_blocks.2.1.weight\", \"backbone.fpn.layer_blocks.2.1.bias\", \"backbone.fpn.layer_blocks.2.1.running_mean\", \"backbone.fpn.layer_blocks.2.1.running_var\", \"backbone.fpn.layer_blocks.3.1.weight\", \"backbone.fpn.layer_blocks.3.1.bias\", \"backbone.fpn.layer_blocks.3.1.running_mean\", \"backbone.fpn.layer_blocks.3.1.running_var\", \"rpn.head.conv.1.0.weight\", \"rpn.head.conv.1.0.bias\", \"roi_heads.box_head.0.0.weight\", \"roi_heads.box_head.0.1.weight\", \"roi_heads.box_head.0.1.bias\", \"roi_heads.box_head.0.1.running_mean\", \"roi_heads.box_head.0.1.running_var\", \"roi_heads.box_head.1.0.weight\", \"roi_heads.box_head.1.1.weight\", \"roi_heads.box_head.1.1.bias\", \"roi_heads.box_head.1.1.running_mean\", \"roi_heads.box_head.1.1.running_var\", \"roi_heads.box_head.2.0.weight\", \"roi_heads.box_head.2.1.weight\", \"roi_heads.box_head.2.1.bias\", \"roi_heads.box_head.2.1.running_mean\", \"roi_heads.box_head.2.1.running_var\", \"roi_heads.box_head.3.0.weight\", \"roi_heads.box_head.3.1.weight\", \"roi_heads.box_head.3.1.bias\", \"roi_heads.box_head.3.1.running_mean\", \"roi_heads.box_head.3.1.running_var\", \"roi_heads.box_head.5.weight\", \"roi_heads.box_head.5.bias\". \n\tUnexpected key(s) in state_dict: \"backbone.fpn.inner_blocks.0.0.bias\", \"backbone.fpn.inner_blocks.1.0.bias\", \"backbone.fpn.inner_blocks.2.0.bias\", \"backbone.fpn.inner_blocks.3.0.bias\", \"backbone.fpn.layer_blocks.0.0.bias\", \"backbone.fpn.layer_blocks.1.0.bias\", \"backbone.fpn.layer_blocks.2.0.bias\", \"backbone.fpn.layer_blocks.3.0.bias\", \"roi_heads.box_head.fc6.weight\", \"roi_heads.box_head.fc6.bias\", \"roi_heads.box_head.fc7.weight\", \"roi_heads.box_head.fc7.bias\". "]}],"source":["ART = Path(\"./artifacts\")\n","with open(ART/\"idx_to_cat_id.json\") as f: IDX_TO_CAT = {int(k): int(v) for k,v in json.load(f).items()}\n","WEIGHTS = ART/\"model_best.pth\"   # or model_last.pth\n","\n","from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2\n","model = fasterrcnn_resnet50_fpn_v2(num_classes=val_state[\"num_classes\"]).to(DEVICE)\n","model.load_state_dict(torch.load(WEIGHTS, map_location=DEVICE))\n","model.eval()\n","\n","@torch.no_grad()\n","def run_inference(model, loader, idx_to_cat_id, score_thr=0.001):\n","    results = []\n","    for images, targets in tqdm(loader, desc=\"Infer\", leave=False):\n","        images = [im.to(DEVICE, non_blocking=True) for im in images]\n","        outputs = model(images)\n","        for out, targ in zip(outputs, targets):\n","            img_id = int(targ[\"image_id\"].item())\n","            boxes  = out[\"boxes\"].detach().cpu().numpy()\n","            scores = out[\"scores\"].detach().cpu().numpy()\n","            labels = out[\"labels\"].detach().cpu().numpy()\n","            for (x1,y1,x2,y2), s, lb in zip(boxes, scores, labels):\n","                if s < score_thr:\n","                    continue\n","                results.append({\n","                    \"image_id\": img_id,\n","                    \"category_id\": int(idx_to_cat_id[int(lb)]),\n","                    \"bbox\": [float(x1), float(y1), float(x2-x1), float(y2-y1)],\n","                    \"score\": float(s),\n","                })\n","    return results\n","\n","# run + mAP\n","val_results = run_inference(model, val_loader, IDX_TO_CAT, score_thr=0.001)\n","with tempfile.NamedTemporaryFile(mode=\"w+\", suffix=\".json\", delete=False) as f:\n","    json.dump(val_results, f); res_json_path = f.name\n","\n","coco_gt = COCO(str(VAL_JSON))\n","coco_dt = coco_gt.loadRes(res_json_path)\n","coco_eval = COCOeval(coco_gt, coco_dt, iouType=\"bbox\")\n","coco_eval.evaluate(); coco_eval.accumulate(); coco_eval.summarize()\n","print(\"Primary mAP@[.50:.95]:\", float(coco_eval.stats[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"f_11lsR8QesS"},"outputs":[],"source":["# EPOCHS = 5  # full epochs on heads; adjust as you like\n","# best_map = -1.0\n","# best_path = \"fasterrcnn_heads_only_best.pth\"\n","\n","# IDX_TO_CAT = train_state['idx_to_cat_id']\n","\n","# for epoch in range(1, EPOCHS+1):\n","#     t0 = time.time()\n","#     train_loss = train_one_epoch(model, train_loader, optimizer, scaler)\n","#     scheduler.step()\n","\n","#     # Validation → COCO mAP\n","#     import json, tempfile\n","#     from pycocotools.coco import COCO\n","#     from pycocotools.cocoeval import COCOeval\n","\n","#     val_results = run_inference(model, val_loader, IDX_TO_CAT, score_thr=0.001)\n","\n","#     with tempfile.NamedTemporaryFile(mode=\"w+\", suffix=\".json\", delete=False) as f:\n","#         json.dump(val_results, f)\n","#         res_json_path = f.name\n","\n","#     coco_gt = COCO(VAL_JSON)\n","#     coco_dt = coco_gt.loadRes(res_json_path)\n","#     coco_eval = COCOeval(coco_gt, coco_dt, iouType=\"bbox\")\n","#     coco_eval.evaluate(); coco_eval.accumulate()\n","#     # capture COCO summary (coco_eval.stats: AP@[.50:.95], AP50, AP75, APS, APM, APL, AR1, AR10, AR100, ARS, ARM, ARL)\n","#     coco_eval.summarize()\n","#     ap = float(coco_eval.stats[0])  # primary mAP@[.50:.95]\n","\n","#     if ap > best_map:\n","#         best_map = ap\n","#         torch.save(model.state_dict(), best_path)\n","\n","#     dt = time.time() - t0\n","#     print(f\"Epoch {epoch}/{EPOCHS} | train_loss={train_loss:.4f} | mAP={ap:.4f} | best_mAP={best_map:.4f} | {dt:.1f}s\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"dcy1Ae_Ud4BL"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyNy0wCCZQpeFVNi6nNE+S7K"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"069aa2dd531540abb060a71a91a84a37":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1735807ded694b60a4a642aac803dbe0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bf99a10cac15491491ee550a6fb2cf6e","IPY_MODEL_968acb627f28424291917f4bed92f36a","IPY_MODEL_9ba8a9df754a4eff8113ccde9d82f17e"],"layout":"IPY_MODEL_a60dcce7b6be42bfb54530c81a6ba620"}},"224b61dbb3464ca69eb4ff2980a58f0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"247549826d45430da46b245c1d619c5f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b022947e6d14b0f9e34a31757ed1f63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3c035419edfe4d18ae0e4566a400ee15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d147178aa9914cc6a7270be97a78d0f5","placeholder":"​","style":"IPY_MODEL_548929578f284b9b9ba2ac901225d55b","value":" 2413/4169 [03:00&lt;02:05, 14.02it/s]"}},"4f9a82ad65694719aad40dc76a020342":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"548929578f284b9b9ba2ac901225d55b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d0935170e2047bb83fb78c741e81075":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5ef6a8f76ba04ad7a9ce20f6c3fe70f3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e0aa39b4d9e4108a1734c5e0cda2e3e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"702e0a41a95049b892b6aed1a632d4e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ef6a8f76ba04ad7a9ce20f6c3fe70f3","max":4169,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5d0935170e2047bb83fb78c741e81075","value":4169}},"7c22e7602dbb4c579486592bd368032e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"83bf3697f7f64ff2bfcdea0964db34cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a0baafe0b5f427c9708bcecece78897":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"94c5a6b94d9d4deaa04623a744962b63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"968acb627f28424291917f4bed92f36a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_83bf3697f7f64ff2bfcdea0964db34cb","max":4169,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8a0baafe0b5f427c9708bcecece78897","value":4169}},"9781f9ebf23d4c0bb3162102e2098bb8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ba8a9df754a4eff8113ccde9d82f17e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f9a82ad65694719aad40dc76a020342","placeholder":"​","style":"IPY_MODEL_9cc391023ded43cf8a489029d4579ba8","value":" 4168/4169 [05:24&lt;00:00, 14.15it/s]"}},"9c269b2cb484442d8019be2718d5521e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cc391023ded43cf8a489029d4579ba8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3884dcbb32b43ecbdf20590a5d8dd22":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7181656aeb940e78613504569ec88f9","max":4169,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b022947e6d14b0f9e34a31757ed1f63","value":2413}},"a60dcce7b6be42bfb54530c81a6ba620":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"a8bbdc41fea54a83bd5707e20554cded":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e328b3054dfe421881ffb4961ddf4855","IPY_MODEL_a3884dcbb32b43ecbdf20590a5d8dd22","IPY_MODEL_3c035419edfe4d18ae0e4566a400ee15"],"layout":"IPY_MODEL_069aa2dd531540abb060a71a91a84a37"}},"b42491b642dc444ca2be6d81509212f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_247549826d45430da46b245c1d619c5f","placeholder":"​","style":"IPY_MODEL_6e0aa39b4d9e4108a1734c5e0cda2e3e","value":"Train: 100%"}},"be221bc7f8414b2084123de01b0066ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3f74de924ea48e9855a5529d130b953","placeholder":"​","style":"IPY_MODEL_fecd0a0664a34d59bc53b02dd0423adb","value":" 4169/4169 [23:14&lt;00:00,  3.25it/s]"}},"bf99a10cac15491491ee550a6fb2cf6e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c269b2cb484442d8019be2718d5521e","placeholder":"​","style":"IPY_MODEL_224b61dbb3464ca69eb4ff2980a58f0d","value":"Train: 100%"}},"c3f74de924ea48e9855a5529d130b953":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d147178aa9914cc6a7270be97a78d0f5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7181656aeb940e78613504569ec88f9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2d4e2b4895b4d1b9c36efc460bee753":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b42491b642dc444ca2be6d81509212f6","IPY_MODEL_702e0a41a95049b892b6aed1a632d4e6","IPY_MODEL_be221bc7f8414b2084123de01b0066ee"],"layout":"IPY_MODEL_7c22e7602dbb4c579486592bd368032e"}},"e328b3054dfe421881ffb4961ddf4855":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9781f9ebf23d4c0bb3162102e2098bb8","placeholder":"​","style":"IPY_MODEL_94c5a6b94d9d4deaa04623a744962b63","value":"Train:  58%"}},"fecd0a0664a34d59bc53b02dd0423adb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}