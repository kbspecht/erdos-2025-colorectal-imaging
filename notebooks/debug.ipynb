{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d139b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "955a89ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faster_rcnn package at: /Users/rebekaheichberg/Desktop/git-re/colorectal_imaging/Architectures/src/faster_rcnn/__init__.py\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "root = Path(\"/Users/rebekaheichberg/Desktop/git-re/colorectal_imaging/Architectures\")\n",
    "\n",
    "# IMPORTANT: add src, not project root\n",
    "sys.path.append(str(root / \"src\"))\n",
    "\n",
    "# Sanity test: this should now work\n",
    "import faster_rcnn\n",
    "print(\"faster_rcnn package at:\", faster_rcnn.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aca791b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rebekaheichberg/Desktop/git-re/colorectal_imaging/Architectures/src/faster_rcnn/augmentations/presets_faster_rcnn.py:289: UserWarning: Argument(s) 'cval' are not valid for transform Affine\n",
      "  A.Affine(  # replaces ShiftScaleRotate\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "root = Path(\"/Users/rebekaheichberg/Desktop/git-re/colorectal_imaging/Architectures\")\n",
    "sys.path.append(str(root / \"src\"))\n",
    "\n",
    "from faster_rcnn.data.data_loaders_faster_rcnn import build_train_val_loaders\n",
    "\n",
    "ckpt_path   = root / \"runs\" / \"frcnn_polyp\" / \"epoch_009.pth\"\n",
    "train_json  = root / \"src\" / \"artifacts\" / \"train.json\"\n",
    "val_json    = root / \"src\" / \"artifacts\" / \"val.json\"\n",
    "roots_map   = root / \"src\" / \"artifacts\" / \"roots_map.json\"\n",
    "images_root = root / \"src\" / \"faster_rcnn\" / \"data\" / \"center_stratified\"\n",
    "\n",
    "train_loader, val_loader = build_train_val_loaders(\n",
    "    train_json=str(train_json),\n",
    "    val_json=str(val_json),\n",
    "    roots_map=str(roots_map),\n",
    "    images_root=str(images_root),\n",
    "    img_size=832,           # only affects TRAIN augs\n",
    "    train_augs=\"light\",\n",
    "    batch_size=2,\n",
    "    num_workers=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95a35ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val tensor size: (1440, 1080)\n",
      "image_ids: [1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rebekaheichberg/anaconda3/envs/erdos_summer_2025/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "images, targets = next(iter(val_loader))\n",
    "img = images[0]\n",
    "_, H_t, W_t = img.shape\n",
    "print(\"val tensor size:\", (W_t, H_t))\n",
    "print(\"image_ids:\", [int(t[\"image_id\"]) for t in targets])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e6af7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO eval:   0%|                                                             | 0/20 [03:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/20] processed 24 detections\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     31\u001b[39m _, val_loader = build_train_val_loaders(\n\u001b[32m     32\u001b[39m     train_json=\u001b[38;5;28mstr\u001b[39m(train_json),\n\u001b[32m     33\u001b[39m     val_json=\u001b[38;5;28mstr\u001b[39m(val_json),\n\u001b[32m   (...)\u001b[39m\u001b[32m     39\u001b[39m     num_workers=\u001b[32m0\u001b[39m,\n\u001b[32m     40\u001b[39m )\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# --- run COCO eval ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m stats = \u001b[43mcoco_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcoco_gt_json\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_json\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# final COCO summary\u001b[39;49;00m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterim_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# set False if it feels too slow / spammy\u001b[39;49;00m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# you can bump this to 5/10/etc for fewer interim evals\u001b[39;49;00m\n\u001b[32m     51\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(stats)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/erdos_summer_2025/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/git-re/colorectal_imaging/Architectures/src/faster_rcnn/data/coco_eval_faster_rcnn.py:327\u001b[39m, in \u001b[36mcoco_map\u001b[39m\u001b[34m(model, loader, device, coco_gt_json, verbose, interim_eval, print_every)\u001b[39m\n\u001b[32m    325\u001b[39m             ev.evaluate()\n\u001b[32m    326\u001b[39m             ev.accumulate()\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m             mAP_50_95, mAP_50 = \u001b[43mev\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstats\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m, ev.stats[\u001b[32m1\u001b[39m]\n\u001b[32m    328\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   interim mAP@[.5:.95]=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmAP_50_95\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, mAP@.5=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmAP_50\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# --- final evaluation ---\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# Add your src folder to Python path\n",
    "SRC = Path(\"/Users/rebekaheichberg/Desktop/git-re/colorectal_imaging/Architectures/src\")\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "\n",
    "from faster_rcnn.data.data_loaders_faster_rcnn import build_train_val_loaders\n",
    "from faster_rcnn.data.coco_eval_faster_rcnn import coco_map\n",
    "from faster_rcnn.models.faster_rcnn_model import build_fasterrcnn\n",
    "\n",
    "# --- paths ---\n",
    "root = Path(\"/Users/rebekaheichberg/Desktop/git-re/colorectal_imaging/Architectures\")\n",
    "ckpt_path  = root / \"runs\" / \"frcnn_polyp\" / \"epoch_009.pth\"\n",
    "train_json = root / \"src\" / \"artifacts\" / \"train.json\"\n",
    "val_json   = root / \"src\" / \"artifacts\" / \"val.json\"\n",
    "roots_map  = root / \"src\" / \"artifacts\" / \"roots_map.json\"\n",
    "images_root = root / \"src\" / \"faster_rcnn\" / \"data\" / \"center_stratified\"\n",
    "\n",
    "# --- setup model ---\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = build_fasterrcnn(num_classes=2, pretrained=False)\n",
    "state = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(state[\"model\"])\n",
    "model.to(device).eval()\n",
    "\n",
    "# --- build validation loader ---\n",
    "_, val_loader = build_train_val_loaders(\n",
    "    train_json=str(train_json),\n",
    "    val_json=str(val_json),\n",
    "    roots_map=str(roots_map),\n",
    "    images_root=str(images_root),\n",
    "    img_size=832,        # used for TRAIN; val uses build_val_augs\n",
    "    train_augs=\"light\",  # doesn't affect val\n",
    "    batch_size=2,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "# --- run COCO eval ---\n",
    "stats = coco_map(\n",
    "    model,\n",
    "    val_loader,\n",
    "    device,\n",
    "    coco_gt_json=str(val_json),\n",
    "    verbose=True,        # final COCO summary\n",
    "    interim_eval=True,   # set False if it feels too slow / spammy\n",
    "    print_every=1        # you can bump this to 5/10/etc for fewer interim evals\n",
    ")\n",
    "print(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "758c298a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rebekaheichberg/Desktop/git-re/colorectal_imaging/Architectures/src/faster_rcnn/augmentations/presets_faster_rcnn.py:289: UserWarning: Argument(s) 'cval' are not valid for transform Affine\n",
      "  A.Affine(  # replaces ShiftScaleRotate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO eval:   0%|                                                             | 0/20 [00:00<?, ?it/s]/Users/rebekaheichberg/anaconda3/envs/erdos_summer_2025/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "COCO eval:   5%|â–ˆâ–ˆâ–Œ                                                 | 1/20 [03:04<58:28, 184.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 1/20] cumulative detections: 24\n",
      "   top scores this batch: [0.98159605 0.94629735 0.73693657]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO eval:  10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                              | 2/20 [06:04<54:37, 182.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 2/20] cumulative detections: 42\n",
      "   top scores this batch: [0.98778033 0.5807748  0.34225145]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO eval:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                            | 3/20 [09:04<51:12, 180.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 3/20] cumulative detections: 65\n",
      "   top scores this batch: [0.7250115  0.71013767 0.6732673 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO eval:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                         | 4/20 [12:06<48:20, 181.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 4/20] cumulative detections: 87\n",
      "   top scores this batch: [0.92078626 0.42951906 0.28007632]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO eval:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                       | 5/20 [15:07<45:20, 181.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 5/20] cumulative detections: 102\n",
      "   top scores this batch: [0.99347466 0.14129077 0.13069433]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO eval:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                    | 6/20 [18:07<42:10, 180.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 6/20] cumulative detections: 118\n",
      "   top scores this batch: [0.9600562 0.9386277 0.3777076]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO eval:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                 | 7/20 [21:15<39:42, 183.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 7/20] cumulative detections: 147\n",
      "   top scores this batch: [0.7498383 0.6957679 0.6615633]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO eval:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                               | 8/20 [24:15<36:25, 182.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 8/20] cumulative detections: 179\n",
      "   top scores this batch: [0.3775249  0.14643587 0.11472232]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO eval:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                            | 9/20 [27:17<33:23, 182.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 9/20] cumulative detections: 196\n",
      "   top scores this batch: [0.69583315 0.62937564 0.46831605]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO eval:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 10/20 [30:18<30:18, 181.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 10/20] cumulative detections: 215\n",
      "   top scores this batch: [0.9805502  0.8538144  0.20420535]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO eval:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 11/20 [33:23<27:24, 182.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 11/20] cumulative detections: 248\n",
      "   top scores this batch: [0.9500707  0.62327784 0.5131574 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO eval:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 12/20 [36:21<24:11, 181.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 12/20] cumulative detections: 268\n",
      "   top scores this batch: [0.89215153 0.75969934 0.65379244]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO eval:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 13/20 [39:20<21:03, 180.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 13/20] cumulative detections: 282\n",
      "   top scores this batch: [0.99281937 0.26185477 0.22233616]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO eval:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 14/20 [42:20<18:02, 180.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 14/20] cumulative detections: 303\n",
      "   top scores this batch: [0.93815565 0.74644893 0.4838316 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO eval:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž            | 15/20 [45:23<15:05, 181.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 15/20] cumulative detections: 313\n",
      "   top scores this batch: [0.07401939 0.0523739 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO eval:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š          | 16/20 [48:25<12:06, 181.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 16/20] cumulative detections: 337\n",
      "   top scores this batch: [0.96061665 0.23058088 0.15330628]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO eval:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž       | 17/20 [51:24<09:02, 180.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 17/20] cumulative detections: 368\n",
      "   top scores this batch: [0.9745106  0.84619766 0.5198742 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO eval:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 18/20 [54:24<06:01, 180.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 18/20] cumulative detections: 395\n",
      "   top scores this batch: [0.979199  0.6697963 0.4877494]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO eval:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 19/20 [57:24<03:00, 180.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 19/20] cumulative detections: 406\n",
      "   top scores this batch: [0.74590045 0.46069196 0.20074451]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COCO eval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [58:40<00:00, 176.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 20/20] cumulative detections: 421\n",
      "   top scores this batch: [0.71712273 0.59059113 0.49000624]\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.04s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.452\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.730\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.541\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.081\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.511\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.404\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.578\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.578\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.623\n",
      "\n",
      "Final metrics:\n",
      "  mAP@[.5:.95] = 0.4524\n",
      "  mAP@0.5      = 0.7300\n",
      "  Recall       = 0.5780\n",
      "  Precision    = 0.4524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# Add your src folder to Python path\n",
    "SRC = Path(\"/Users/rebekaheichberg/Desktop/git-re/colorectal_imaging/Architectures/src\")\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "\n",
    "from faster_rcnn.data.data_loaders_faster_rcnn import build_train_val_loaders\n",
    "from faster_rcnn.data.coco_eval_faster_rcnn import coco_map\n",
    "from faster_rcnn.models.faster_rcnn_model import build_fasterrcnn\n",
    "\n",
    "# --- paths ---\n",
    "root = Path(\"/Users/rebekaheichberg/Desktop/git-re/colorectal_imaging/Architectures\")\n",
    "ckpt_path  = root / \"runs\" / \"frcnn_polyp\" / \"epoch_009.pth\"\n",
    "train_json = root / \"src\" / \"artifacts\" / \"train.json\"\n",
    "val_json   = root / \"src\" / \"artifacts\" / \"val.json\"\n",
    "roots_map  = root / \"src\" / \"artifacts\" / \"roots_map.json\"\n",
    "images_root = root / \"src\" / \"faster_rcnn\" / \"data\" / \"center_stratified\"\n",
    "\n",
    "# --- setup model ---\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = build_fasterrcnn(num_classes=2, pretrained=False)\n",
    "state = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(state[\"model\"])\n",
    "model.to(device).eval()\n",
    "\n",
    "# --- build validation loader ---\n",
    "_, val_loader = build_train_val_loaders(\n",
    "    train_json=str(train_json),\n",
    "    val_json=str(val_json),\n",
    "    roots_map=str(roots_map),\n",
    "    images_root=str(images_root),\n",
    "    img_size=832,        # affects TRAIN only; val uses build_val_augs\n",
    "    train_augs=\"light\",\n",
    "    batch_size=2,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "# --- run COCO eval ---\n",
    "metrics = coco_map(\n",
    "    model,\n",
    "    val_loader,\n",
    "    device,\n",
    "    coco_gt_json=str(val_json),\n",
    "    verbose=True,     # prints COCO table at the end\n",
    "    log_every=1,      # print per batch; set 5/10 if too chatty\n",
    ")\n",
    "\n",
    "print(\"\\nFinal metrics:\")\n",
    "print(\n",
    "    f\"  mAP@[.5:.95] = {metrics['mAP_50_95']:.4f}\\n\"\n",
    "    f\"  mAP@0.5      = {metrics['mAP_50']:.4f}\\n\"\n",
    "    f\"  Recall       = {metrics['recall']:.4f}\\n\"\n",
    "    f\"  Precision    = {metrics['precision']:.4f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfef5906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/rebekaheichberg/Desktop/git-re/colorectal_imaging/Architectures/notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a24d3d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 0, 'box': [655.8455810546875, 626.7365112304688, 766.4119262695312, 754.4381103515625], 'score': 0.981596052646637}, {'id': 1, 'box': [422.2256164550781, 485.1336669921875, 530.6296997070312, 574.904052734375], 'score': 0.9462974667549133}, {'id': 2, 'box': [786.2018432617188, 235.1293182373047, 836.5023193359375, 281.91192626953125], 'score': 0.7369361519813538}, {'id': 3, 'box': [777.5625610351562, 581.8145141601562, 848.9518432617188, 653.7422485351562], 'score': 0.5375287532806396}]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from faster_rcnn.deploy.inference_service import *\n",
    "\n",
    "model = load_model()\n",
    "img = Image.open(\"/Users/rebekaheichberg/Desktop/git-re/colorectal_imaging/Architectures/src/faster_rcnn/data/center_stratified/C3/images/val/c3s000p4_0d17_C3_EndoCV2021_00180.jpg\")\n",
    "preds = run_inference(model, img, score_thr=0.3)\n",
    "print(preds)\n",
    "img_with_boxes = draw_boxes(img, preds)\n",
    "img_with_boxes.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c28e958d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      ðŸ‘‹ \u001b[1mWelcome to Streamlit!\u001b[0m\n",
      "\n",
      "      If you'd like to receive helpful onboarding emails, news, offers, promotions,\n",
      "      and the occasional swag, please enter your email address below. Otherwise,\n",
      "      leave this field blank.\n",
      "\n",
      "      \u001b[34mEmail: \u001b[0m ^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run ../src/faster_rcnn/deploy/streamlit_app.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e09b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /Users/rebekaheichberg/Desktop/git-re/colorectal_imaging/Architectures\n",
    "PYTHONPATH=src:$PYTHONPATH streamlit run src/faster_rcnn/deploy/streamlit_app.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_summer_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
